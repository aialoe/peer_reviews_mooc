{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d5ce55-08de-448f-a9b3-2e2b7b64ccf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1561d59-54e5-44e2-b299-e62517c13184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('/home/jovyan/shared/2020_06_10_bad_reviewer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb84fc-c4bb-4f48-a068-2980467ed51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9596c571-6ec5-4674-af20-d640139c48e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peer_review_id                                             1084657\n",
       "uva_peer_assignments_user_id_reviewer                      1084657\n",
       "peer_review_created_ts                                     1084657\n",
       "peer_submission_id                                         1084657\n",
       "peer_assignment_review_schema_part_prompt_score             929706\n",
       "peer_assignment_review_schema_part_option_score             929706\n",
       "peer_assignment_review_schema_part_prompt_free_response    1084640\n",
       "peer_review_part_free_response_text                        1059044\n",
       "uva_peer_assignments_user_id_author                         864073\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data views\n",
    "labelled_txts = pd.read_json('data/labelled_subs_with_posts.jsonl', orient='records', lines=True)\n",
    "labelled_txts['id'] = labelled_txts['id'].str.split('_').str[1]\n",
    "labelled_txts = labelled_txts.rename(columns={'id':'uva_peer_assignments_user_id_author', 'data':'text'})\n",
    "\n",
    "texts_df = pd.read_csv('data/texts_with_peer_reviews.csv', index_col=[0])\n",
    "data_view_df = pd.read_csv('data/data_view_for_peer_review_analysis.csv', escapechar='\\\\', on_bad_lines='warn', index_col=[0])\n",
    "reviewer_df = pd.read_csv('results/reviewer_agg_stats.csv', index_col=[0])\n",
    "cleared_submissions = pd.read_csv('bin/cleared_submissions.csv')\n",
    "submissions_df = pd.read_csv('bin/submissions_df.csv', index_col=[0])\n",
    "reviews_df = pd.read_csv('bin/reviews_df.csv', index_col = [0])\n",
    "\n",
    "# Rename the columns to disambiguate whether the id represents a reviewer or an author\n",
    "submissions_df = submissions_df.rename(columns={'uva_peer_assignments_user_id':'uva_peer_assignments_user_id_author'})\n",
    "reviewer_df = reviewer_df.rename(columns={'uva_peer_assignments_user_id':'uva_peer_assignments_user_id_reviewer'})\n",
    "reviews_df = reviews_df.rename(columns={'uva_peer_assignments_user_id':'uva_peer_assignments_user_id_reviewer'})\n",
    "cleared_submissions = cleared_submissions.rename(columns={'uva_peer_assignments_user_id':'uva_peer_assignments_user_id_author'})\n",
    "\n",
    "# Get the author id into reviews_df\n",
    "reviews_df = pd.merge(reviews_df, cleared_submissions[['peer_submission_id', 'uva_peer_assignments_user_id_author']], on='peer_submission_id', how=\"left\")\n",
    "# Note that authors could only be found for 864,073 out of the 1,059,044 reviews.\n",
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4cddc-7d0f-4a07-a787-16c86bc32d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2081a45-107d-4bc5-822a-5138a0a292c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate essays\n",
    "print(len(labelled_txts))\n",
    "submissions_df['is_duplicate'] = submissions_df.duplicated(subset=['text'], keep=False)\n",
    "labelled_txts=submissions_df[['is_duplicate', 'uva_peer_assignments_user_id_author']].merge(labelled_txts, on='uva_peer_assignments_user_id_author', how='inner')\n",
    "labelled_txts = labelled_txts[labelled_txts['is_duplicate'] == False]\n",
    "print(len(labelled_txts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40963f1-7c65-454c-8a2d-8225dfd32d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f873b-b864-4b0f-b205-7f11b4a3cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of words for the labelled texts\n",
    "labelled_txts['num_words'] = labelled_txts.apply(lambda row: len(row['text'].split()), axis=1)\n",
    "\n",
    "reviewer_df['total_variance'] = reviewer_df['total_sd']**2\n",
    "reviewer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06340adf-6dfe-4a19-9eec-032cc25875e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d5c82-3907-4297-9392-049b765a6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Include All Reviewers\n",
    "\n",
    "def pruneReviewers():\n",
    "    good_reviewers_df = reviewer_df[reviewer_df['total_variance']>=0][['uva_peer_assignments_user_id_reviewer']]\n",
    "    good_reviewers_df['good_reviewer'] = True\n",
    "    return good_reviewers_df\n",
    "\n",
    "labelled_data = labelled_txts.merge(reviews_df, on='uva_peer_assignments_user_id_author', how='left')\n",
    "print(len(labelled_txts), len(set(labelled_data['uva_peer_assignments_user_id_author'])))\n",
    "\n",
    "# essay_scores contains, author id, reviewer id, submission id, and the sum score for each review\n",
    "essay_scores = labelled_data.groupby(['uva_peer_assignments_user_id_reviewer', 'peer_submission_id', 'uva_peer_assignments_user_id_author']).agg({'peer_assignment_review_schema_part_option_score':'sum'}).reset_index()\n",
    "# check to make sure it looks valid\n",
    "print('checking for non-null values\\n' , essay_scores.count(), sep='')\n",
    "print('num of reviews:', len(essay_scores))\n",
    "print('num of authors:', essay_scores['uva_peer_assignments_user_id_author'].nunique())\n",
    "\n",
    "good_reviewers = pruneReviewers()\n",
    "# Merge essay scores with good reviewers and keep only reviews by good reviewers\n",
    "essay_scores_good_reviewers = good_reviewers.merge(essay_scores, on='uva_peer_assignments_user_id_reviewer', how='right')\n",
    "essay_scores_good_only = essay_scores_good_reviewers[essay_scores_good_reviewers['good_reviewer'] == True]\n",
    "# Create a dataframe of submission ids of submissions reviewed by at least two good reviewers\n",
    "good_reviewers_df = essay_scores_good_only.groupby('peer_submission_id').agg({'good_reviewer':'sum'}).reset_index()\n",
    "good_reviewers_df = good_reviewers_df[good_reviewers_df['good_reviewer'] >= 2].rename(columns={'good_reviewer':'num_reviews'})\n",
    "# Merge essay scores with good reviewers in order to remove submissions with less than two good reviewers\n",
    "essay_scores_good_labelled = essay_scores_good_only.merge(good_reviewers_df, on='peer_submission_id', how='right')\n",
    "# Collect average scores for each submission\n",
    "essay_scores_final = essay_scores_good_labelled.groupby(['peer_submission_id', 'uva_peer_assignments_user_id_author']).agg({'peer_assignment_review_schema_part_option_score':'mean'}).reset_index()\n",
    "corr_df = essay_scores_final[['uva_peer_assignments_user_id_author',\n",
    "                                  'peer_assignment_review_schema_part_option_score']].drop_duplicates().merge(labelled_txts[['uva_peer_assignments_user_id_author', \n",
    "                                                                                                                 'num_words']].drop_duplicates(), on='uva_peer_assignments_user_id_author', how='left')\n",
    "all_reviewers = essay_scores_final.merge(labelled_txts, on='uva_peer_assignments_user_id_author')[['text','peer_assignment_review_schema_part_option_score']].rename(columns = {'peer_assignment_review_schema_part_option_score':'labels'})\n",
    "all_reviewers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
