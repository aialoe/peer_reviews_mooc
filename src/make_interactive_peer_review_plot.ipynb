{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da2e29b-8ee7-42f0-b241-5462014f64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "os.chdir('/home/jovyan/shared/2020_06_10_bad_reviewer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00b74d-ee88-457a-9d5f-cad552ac9474",
   "metadata": {},
   "source": [
    "## Get submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bf7b58-bc21-4804-8ff4-92ad30751cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2735 submissions by users with posts and not also submitted by another user.\n",
      "This is based on the files that were parsed, of course.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_submission_score</th>\n",
       "      <th>num_skips</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27909.000000</td>\n",
       "      <td>27909.000000</td>\n",
       "      <td>27909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.593088</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>677.555484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.889616</td>\n",
       "      <td>0.128517</td>\n",
       "      <td>286.356858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>844.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4041.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       peer_submission_score     num_skips    word_count\n",
       "count           27909.000000  27909.000000  27909.000000\n",
       "mean               16.593088      0.014726    677.555484\n",
       "std                 1.889616      0.128517    286.356858\n",
       "min                 6.000000      0.000000     35.000000\n",
       "25%                16.000000      0.000000    485.000000\n",
       "50%                18.000000      0.000000    652.000000\n",
       "75%                18.000000      0.000000    844.000000\n",
       "max                18.000000      3.000000   4041.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All texts that were parsed\n",
    "submissions_df = pd.read_csv('bin/submissions_df.csv', index_col=[0])\n",
    "\n",
    "# This marks exactly identical texts as duplicates\n",
    "# We may want to go further and look for similar texts using some heuristic\n",
    "assert not submissions_df.duplicated(subset=['uva_peer_assignments_user_id'], keep=False).all() # There are no duplicate user_ids\n",
    "submissions_df['is_duplicate'] = submissions_df.duplicated(subset=['text'], keep=False) # All duplicate texts must therefore come from different users\n",
    "\n",
    "print(f'We have {submissions_df[submissions_df.has_post & ~submissions_df.is_duplicate].shape[0]} submissions by users with posts and not also submitted by another user.')\n",
    "print('This is based on the files that were parsed, of course.')\n",
    "\n",
    "# Get simple token count\n",
    "# submissions_df['word_count'] = submissions_df.text.str.split().str.len()\n",
    "\n",
    "# Get NLTK word count\n",
    "## This takes a minute because pandas apply just runs on one core\n",
    "## We could multithread this using Dask, but it's not worth the trouble here\n",
    "submissions_df['text'] = submissions_df.text.apply(lambda x: nltk.word_tokenize(x) if pd.notnull(x) else [])\n",
    "submissions_df['word_count'] = submissions_df.text.str.len()\n",
    "\n",
    "submissions_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597e88c-3766-404e-9c54-4d68410f50bd",
   "metadata": {},
   "source": [
    "## Get reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf2df05-2fea-44ab-abbe-5fac0abd1cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_review_id</th>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th>peer_review_created_ts</th>\n",
       "      <th>peer_submission_id</th>\n",
       "      <th>peer_assignment_review_schema_part_prompt_score</th>\n",
       "      <th>peer_assignment_review_schema_part_option_score</th>\n",
       "      <th>peer_assignment_review_schema_part_prompt_free_response</th>\n",
       "      <th>peer_review_part_free_response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Challenge (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s challenge...</td>\n",
       "      <td>[search, for, higher, ground]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Selection (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s tool sele...</td>\n",
       "      <td>[removing, barriers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Application (score)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s tool appl...</td>\n",
       "      <td>[understanding, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Insight (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s insight d...</td>\n",
       "      <td>[drilling, down, to, the, essence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Approach (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s approach ...</td>\n",
       "      <td>[increasing, speed, of, learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084652</th>\n",
       "      <td>zztv8lPNEei7NQqkzSZOZA</td>\n",
       "      <td>da809ddc4f894b61d858fa3a38f79aad347c5ddc</td>\n",
       "      <td>2018-05-09 21:13:24.498</td>\n",
       "      <td>L7swSFLyEei3JxKjZPnMdA</td>\n",
       "      <td>Application (score)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Feedback (ungraded): The submission’s tool app...</td>\n",
       "      <td>[Only, went, into, detailing, about, storytell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084653</th>\n",
       "      <td>zztv8lPNEei7NQqkzSZOZA</td>\n",
       "      <td>da809ddc4f894b61d858fa3a38f79aad347c5ddc</td>\n",
       "      <td>2018-05-09 21:13:24.498</td>\n",
       "      <td>L7swSFLyEei3JxKjZPnMdA</td>\n",
       "      <td>Insight (score)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Feedback (ungraded): The submission’s insight ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084654</th>\n",
       "      <td>zztv8lPNEei7NQqkzSZOZA</td>\n",
       "      <td>da809ddc4f894b61d858fa3a38f79aad347c5ddc</td>\n",
       "      <td>2018-05-09 21:13:24.498</td>\n",
       "      <td>L7swSFLyEei3JxKjZPnMdA</td>\n",
       "      <td>Approach (score)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Feedback (ungraded): The submission’s approach...</td>\n",
       "      <td>[Mentions, visualization, but, not, how, they,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084655</th>\n",
       "      <td>zztv8lPNEei7NQqkzSZOZA</td>\n",
       "      <td>da809ddc4f894b61d858fa3a38f79aad347c5ddc</td>\n",
       "      <td>2018-05-09 21:13:24.498</td>\n",
       "      <td>L7swSFLyEei3JxKjZPnMdA</td>\n",
       "      <td>Organization (score)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Feedback (ungraded): The submission’s overall ...</td>\n",
       "      <td>[Developing, the, challenge, further, and, cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084656</th>\n",
       "      <td>zztv8lPNEei7NQqkzSZOZA</td>\n",
       "      <td>da809ddc4f894b61d858fa3a38f79aad347c5ddc</td>\n",
       "      <td>2018-05-09 21:13:24.498</td>\n",
       "      <td>L7swSFLyEei3JxKjZPnMdA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Additional Feedback (ungraded): While reviewin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1084657 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 peer_review_id              uva_peer_assignments_user_id  \\\n",
       "0        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "1        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "2        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "3        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "4        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "...                         ...                                       ...   \n",
       "1084652  zztv8lPNEei7NQqkzSZOZA  da809ddc4f894b61d858fa3a38f79aad347c5ddc   \n",
       "1084653  zztv8lPNEei7NQqkzSZOZA  da809ddc4f894b61d858fa3a38f79aad347c5ddc   \n",
       "1084654  zztv8lPNEei7NQqkzSZOZA  da809ddc4f894b61d858fa3a38f79aad347c5ddc   \n",
       "1084655  zztv8lPNEei7NQqkzSZOZA  da809ddc4f894b61d858fa3a38f79aad347c5ddc   \n",
       "1084656  zztv8lPNEei7NQqkzSZOZA  da809ddc4f894b61d858fa3a38f79aad347c5ddc   \n",
       "\n",
       "          peer_review_created_ts      peer_submission_id  \\\n",
       "0        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "1        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "2        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "3        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "4        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "...                          ...                     ...   \n",
       "1084652  2018-05-09 21:13:24.498  L7swSFLyEei3JxKjZPnMdA   \n",
       "1084653  2018-05-09 21:13:24.498  L7swSFLyEei3JxKjZPnMdA   \n",
       "1084654  2018-05-09 21:13:24.498  L7swSFLyEei3JxKjZPnMdA   \n",
       "1084655  2018-05-09 21:13:24.498  L7swSFLyEei3JxKjZPnMdA   \n",
       "1084656  2018-05-09 21:13:24.498  L7swSFLyEei3JxKjZPnMdA   \n",
       "\n",
       "        peer_assignment_review_schema_part_prompt_score  \\\n",
       "0                                     Challenge (score)   \n",
       "1                                     Selection (score)   \n",
       "2                                   Application (score)   \n",
       "3                                       Insight (score)   \n",
       "4                                      Approach (score)   \n",
       "...                                                 ...   \n",
       "1084652                             Application (score)   \n",
       "1084653                                 Insight (score)   \n",
       "1084654                                Approach (score)   \n",
       "1084655                            Organization (score)   \n",
       "1084656                                             NaN   \n",
       "\n",
       "         peer_assignment_review_schema_part_option_score  \\\n",
       "0                                                    3.0   \n",
       "1                                                    3.0   \n",
       "2                                                    2.0   \n",
       "3                                                    3.0   \n",
       "4                                                    3.0   \n",
       "...                                                  ...   \n",
       "1084652                                              1.0   \n",
       "1084653                                              2.0   \n",
       "1084654                                              1.0   \n",
       "1084655                                              2.0   \n",
       "1084656                                              NaN   \n",
       "\n",
       "        peer_assignment_review_schema_part_prompt_free_response  \\\n",
       "0        Feedback (ungraded):The submission’s challenge...        \n",
       "1        Feedback (ungraded):The submission’s tool sele...        \n",
       "2        Feedback (ungraded):The submission’s tool appl...        \n",
       "3        Feedback (ungraded):The submission’s insight d...        \n",
       "4        Feedback (ungraded):The submission’s approach ...        \n",
       "...                                                    ...        \n",
       "1084652  Feedback (ungraded): The submission’s tool app...        \n",
       "1084653  Feedback (ungraded): The submission’s insight ...        \n",
       "1084654  Feedback (ungraded): The submission’s approach...        \n",
       "1084655  Feedback (ungraded): The submission’s overall ...        \n",
       "1084656  Additional Feedback (ungraded): While reviewin...        \n",
       "\n",
       "                       peer_review_part_free_response_text  \n",
       "0                            [search, for, higher, ground]  \n",
       "1                                     [removing, barriers]  \n",
       "2                                      [understanding, it]  \n",
       "3                       [drilling, down, to, the, essence]  \n",
       "4                        [increasing, speed, of, learning]  \n",
       "...                                                    ...  \n",
       "1084652  [Only, went, into, detailing, about, storytell...  \n",
       "1084653                                                 []  \n",
       "1084654  [Mentions, visualization, but, not, how, they,...  \n",
       "1084655  [Developing, the, challenge, further, and, cle...  \n",
       "1084656                                                 []  \n",
       "\n",
       "[1084657 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('bin/reviews_df.csv', index_col=[0])\n",
    "\n",
    "## Takes a minute\n",
    "reviews_df['peer_review_part_free_response_text'] = reviews_df['peer_review_part_free_response_text'].apply(lambda x: nltk.word_tokenize(x) if pd.notnull(x) else [])\n",
    "display(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f749a4e-edab-4bbf-9fa2-613fe89b2df2",
   "metadata": {},
   "source": [
    "## Get Reviewer Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ad8962-592b-4b85-a6d9-9c292ae47164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ttr</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000e5af02da0c7575b3ebd346b55b29f959e90f</th>\n",
       "      <td>0.484185</td>\n",
       "      <td>0.832352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002c0f31f5c8456bd360dfcd089a64f444e2de0</th>\n",
       "      <td>0.464497</td>\n",
       "      <td>0.685994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030b378ea62d60a177113b7854eb26cc29e1a9</th>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.832352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000458f7d47a0b6414f9146258829170ae3ed6a9</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00069909160c6bcd9836cdb23e35b1fdaf56d0c3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.383482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff56a1858c62540bd76bad23db07a2fbfa963fe</th>\n",
       "      <td>0.487719</td>\n",
       "      <td>0.900254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff7364558963fb9fa218f2fa08d5d2767992207</th>\n",
       "      <td>0.528662</td>\n",
       "      <td>0.460889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff883a717a37b5699e5105a96d61dc10812cabe</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffa6add42713b8b1e2a5158616f780997bbda49</th>\n",
       "      <td>0.624242</td>\n",
       "      <td>0.511310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffa6e23203663d0be8e6885eb970308528379bb</th>\n",
       "      <td>0.299517</td>\n",
       "      <td>0.427793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ttr        sd\n",
       "uva_peer_assignments_user_id                                \n",
       "0000e5af02da0c7575b3ebd346b55b29f959e90f  0.484185  0.832352\n",
       "0002c0f31f5c8456bd360dfcd089a64f444e2de0  0.464497  0.685994\n",
       "00030b378ea62d60a177113b7854eb26cc29e1a9  0.413333  0.832352\n",
       "000458f7d47a0b6414f9146258829170ae3ed6a9  0.047619  0.000000\n",
       "00069909160c6bcd9836cdb23e35b1fdaf56d0c3  0.333333  0.383482\n",
       "...                                            ...       ...\n",
       "fff56a1858c62540bd76bad23db07a2fbfa963fe  0.487719  0.900254\n",
       "fff7364558963fb9fa218f2fa08d5d2767992207  0.528662  0.460889\n",
       "fff883a717a37b5699e5105a96d61dc10812cabe  0.071429  0.000000\n",
       "fffa6add42713b8b1e2a5158616f780997bbda49  0.624242  0.511310\n",
       "fffa6e23203663d0be8e6885eb970308528379bb  0.299517  0.427793\n",
       "\n",
       "[41243 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ttr(value):\n",
    "    # input is a GroupBy object of token sequences\n",
    "    # we want one long sequence of tokens for each user\n",
    "    flat_list = [tok for toks in value for tok in toks]\n",
    "\n",
    "    # check for zero division and return \n",
    "    if (seq_len := len(flat_list)) > 0:\n",
    "        return len(set(flat_list)) / seq_len\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "reviewer_df = (reviews_df\n",
    "               .groupby('uva_peer_assignments_user_id')\n",
    "               .agg(\n",
    "                   ttr=pd.NamedAgg(column=\"peer_review_part_free_response_text\", aggfunc=ttr),\n",
    "                   sd=pd.NamedAgg(column=\"peer_assignment_review_schema_part_option_score\", aggfunc='std')\n",
    "               ))\n",
    "display(reviewer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4577e96-c989-4714-9534-cf5761d81e58",
   "metadata": {},
   "source": [
    "## Calculate Scores with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e883906-1d19-454b-9cff-a632fe207990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_scores(select_submissions, ttr_tolerance=0, sd_tolerance=0):\n",
    "    return (reviewer_df[(reviewer_df.ttr\n",
    "                        >=\n",
    "                        ttr_tolerance)\n",
    "                        &\n",
    "                        (reviewer_df.sd\n",
    "                        >=\n",
    "                        sd_tolerance)]\n",
    "            .join(reviews_df\n",
    "                 .set_index('uva_peer_assignments_user_id'))\n",
    "            .groupby(['peer_review_id', 'peer_submission_id'])\n",
    "            .agg({'peer_assignment_review_schema_part_option_score': 'sum'})\n",
    "            .groupby('peer_submission_id')\n",
    "            .agg({'peer_assignment_review_schema_part_option_score': 'mean'})\n",
    "            .reindex(pd.Index(select_submissions.peer_submission_id))\n",
    "            .set_index(select_submissions.index)\n",
    "            .peer_assignment_review_schema_part_option_score\n",
    "            .dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084cdb7-d40f-403d-a9b6-f6f05d6b4d0b",
   "metadata": {},
   "source": [
    "## Make an Interactive Plot\n",
    "\n",
    "Not sure if this is useful at all, but it was fun to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd3d41f-3e3b-4889-9989-66d7fa89d7ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m widgets\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c087b27-8894-452c-9d12-955dea5442aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_tolerance = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=0.0,\n",
    "    max=0.5,\n",
    "    step=0.1,\n",
    "    description='SD:',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "ttr_tolerance = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=0.0,\n",
    "    max=0.5,\n",
    "    step=0.1,\n",
    "    description='TTR:',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "### TODO: add intslider for num_reviewers required to calculate score\n",
    "\n",
    "omit_duplicates = widgets.Checkbox(\n",
    "    description='Omit Duplicates',\n",
    "    value=False,\n",
    ")\n",
    "\n",
    "posters_only = widgets.Checkbox(\n",
    "    description='Forum Participants Only',\n",
    "    value=False,\n",
    ")\n",
    "\n",
    "container1 = widgets.HBox(children=[omit_duplicates, posters_only])\n",
    "container2 = widgets.HBox(children=[sd_tolerance, ttr_tolerance])\n",
    "\n",
    "# Coursera calculates peer_submission_score differently,\n",
    "# See getting_peer_review_information.ipynb\n",
    "# We initialize the graph with Coursera scores,\n",
    "# But these will change after the graph updates.\n",
    "X = submissions_df['word_count']\n",
    "Y = submissions_df['peer_submission_score']\n",
    "best_fit = sm.OLS(Y, sm.add_constant(X)).fit().fittedvalues\n",
    "\n",
    "# Assign an empty figure widget with two traces\n",
    "# Scattergl makes it render using WebGL, in your browser\n",
    "trace1 = go.Scattergl(name='ols', x=X, y=best_fit, mode='lines')\n",
    "trace2 = go.Scattergl(name='scores', x=X, y=Y.values, mode='markers')\n",
    "\n",
    "### TODO: Add trace for num essays remaining\n",
    "\n",
    "### TODO: Add Mouse-Hover for R-squared value of OLS line\n",
    "\n",
    "g = go.FigureWidget(data=[trace1\n",
    "                          # , trace2],\n",
    "                         ],\n",
    "                    layout=go.Layout(\n",
    "                        title='Relationship Between Word Count and Calculated Score',\n",
    "                        xaxis={\n",
    "                            'range':[50, 1000],\n",
    "                            'title':'Word Count'\n",
    "                        },\n",
    "                        yaxis={\n",
    "                            'range':[6, 18],\n",
    "                            'title':'Score'\n",
    "                        }\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab8c03-09bd-4290-8a1a-26f1ea9caafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(change):\n",
    "    selected_data = submissions_df\n",
    "    if omit_duplicates.value:\n",
    "        selected_data = selected_data[~selected_data.is_duplicate]\n",
    "    if posters_only.value:\n",
    "        selected_data = selected_data[selected_data.has_post]\n",
    "        \n",
    "    Y2 = recalculate_scores(select_submissions=selected_data,\n",
    "                            ttr_tolerance=ttr_tolerance.value,\n",
    "                            sd_tolerance=sd_tolerance.value)\n",
    "    X2 = X.reindex_like(Y2)\n",
    "    best_fit = sm.OLS(Y2, sm.add_constant(X2)).fit().fittedvalues\n",
    "    \n",
    "    with g.batch_update():\n",
    "        g.data[0].x = X2\n",
    "        g.data[0].y = best_fit # Regression\n",
    "        # g.data[1].x = X2\n",
    "        # g.data[1].y = Y2.values # Scatters\n",
    "        \n",
    "sd_tolerance.observe(response, names=\"value\")\n",
    "ttr_tolerance.observe(response, names=\"value\")\n",
    "omit_duplicates.observe(response, names=\"value\")\n",
    "posters_only.observe(response, names=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746c4de-2817-4206-8d1d-6fdf2c4b7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.VBox([container1,\n",
    "              container2,\n",
    "              g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4b630-829d-44d8-b321-8cec802990e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
