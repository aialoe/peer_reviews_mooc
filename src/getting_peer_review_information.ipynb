{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493ccf50-1291-4c33-885f-42dbc5dc421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/home/jovyan/shared/2020_06_10_bad_reviewer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49d46d-bf1d-40c0-bf31-fd5ede4770cf",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6fb338-61c4-4cbf-ac25-6980832e6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/coursera_tables/peer_reviews.csv',\n",
    "                      usecols=['peer_review_id',\n",
    "                               'peer_submission_id',\n",
    "                               'uva_peer_assignments_user_id',\n",
    "                               'peer_review_created_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306339b1-b04b-435c-baf2-33dbf8ef2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pd.read_csv('data/coursera_tables/peer_assignment_review_schema_parts.csv')\n",
    "schema_options = pd.read_csv('data/coursera_tables/peer_assignment_review_schema_part_options.csv')\n",
    "# display(schema)\n",
    "# display(schema_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a99efd2-d1f0-49df-a2fa-9d325998c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "written_responses = pd.read_csv('data/coursera_tables/peer_review_part_free_responses.csv', escapechar='\\\\', on_bad_lines='warn')\n",
    "score_responses = pd.read_csv('data/coursera_tables/peer_review_part_choices.csv')\n",
    "# display(written_responses)\n",
    "# display(score_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb254a9-ca9a-4a1c-bcb6-9f66ecf2a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_readable_text_responses = written_responses.merge(schema)\n",
    "'''\n",
    "subtract 1 from each schema part order, so the text response schema_part_order has the same value as the score_response before it\n",
    "So if \"Challenge (score)\" has schema_part_order 0 and \"Challenge Feedback (ungraded)\" has schema_part_order 1,\n",
    "We can align these dataviews and get a single row for Challenge, both score and feedback.\n",
    "\n",
    "'''\n",
    "human_readable_text_responses.peer_assignment_review_schema_part_order = human_readable_text_responses.peer_assignment_review_schema_part_order -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2abcd9a-365f-4525-848b-86859ff70dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_review_id</th>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th>peer_review_created_ts</th>\n",
       "      <th>peer_submission_id</th>\n",
       "      <th>peer_assignment_review_schema_part_prompt_score</th>\n",
       "      <th>peer_assignment_review_schema_part_option_score</th>\n",
       "      <th>peer_assignment_review_schema_part_prompt_free_response</th>\n",
       "      <th>peer_review_part_free_response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Challenge (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s challenge...</td>\n",
       "      <td>search for higher ground</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Selection (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s tool sele...</td>\n",
       "      <td>removing barriers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Application (score)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s tool appl...</td>\n",
       "      <td>understanding it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Insight (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s insight d...</td>\n",
       "      <td>drilling down to the essence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--1K-8NvEeqUARLn1lBFnw</td>\n",
       "      <td>b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a</td>\n",
       "      <td>2020-07-11 12:13:52.365</td>\n",
       "      <td>tyljI8NkEeql1A5WxvNUrQ</td>\n",
       "      <td>Approach (score)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Feedback (ungraded):The submission’s approach ...</td>\n",
       "      <td>increasing speed of learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084658</th>\n",
       "      <td>ARYplXxXEeq-IBL6cGi2Cw</td>\n",
       "      <td>a6131cda10617880caeff202f24b9de41fcfa722</td>\n",
       "      <td>2020-04-12 00:46:11.045</td>\n",
       "      <td>C3DnznwuEeqEUA6YVkoxuQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084659</th>\n",
       "      <td>GfkaLiyFEeu4Zgo0ZCoTOQ</td>\n",
       "      <td>8284087aea601fc9b56dd29a473ecc7c65819a8b</td>\n",
       "      <td>2020-11-22 05:39:34.297</td>\n",
       "      <td>bx0OtcZQEeq3ahK57vJ81Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084660</th>\n",
       "      <td>KcruGXxZEeqEUA6YVkoxuQ</td>\n",
       "      <td>ff41433c3431f10ab61b6b89506d88194f8be736</td>\n",
       "      <td>2020-04-12 01:01:38.332</td>\n",
       "      <td>C3DnznwuEeqEUA6YVkoxuQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084661</th>\n",
       "      <td>h0R7LNUwEeqdnQrjXnH35w</td>\n",
       "      <td>49163e3c086ea334b4b145a8a3e61738b957d84b</td>\n",
       "      <td>2020-08-03 02:24:59.278</td>\n",
       "      <td>fOFFBdTSEeqwjRINUYbZPQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084662</th>\n",
       "      <td>wHiX_9UrEeqwjRINUYbZPQ</td>\n",
       "      <td>df92c5ce24d699504f20a754649800d55ec5dfac</td>\n",
       "      <td>2020-08-03 01:50:47.766</td>\n",
       "      <td>_DX3PtTcEeqBeA5fY9gYEQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1084663 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 peer_review_id              uva_peer_assignments_user_id  \\\n",
       "0        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "1        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "2        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "3        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "4        --1K-8NvEeqUARLn1lBFnw  b3a960970d72a6ce0b00c0bdfbccd943b9b64b6a   \n",
       "...                         ...                                       ...   \n",
       "1084658  ARYplXxXEeq-IBL6cGi2Cw  a6131cda10617880caeff202f24b9de41fcfa722   \n",
       "1084659  GfkaLiyFEeu4Zgo0ZCoTOQ  8284087aea601fc9b56dd29a473ecc7c65819a8b   \n",
       "1084660  KcruGXxZEeqEUA6YVkoxuQ  ff41433c3431f10ab61b6b89506d88194f8be736   \n",
       "1084661  h0R7LNUwEeqdnQrjXnH35w  49163e3c086ea334b4b145a8a3e61738b957d84b   \n",
       "1084662  wHiX_9UrEeqwjRINUYbZPQ  df92c5ce24d699504f20a754649800d55ec5dfac   \n",
       "\n",
       "          peer_review_created_ts      peer_submission_id  \\\n",
       "0        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "1        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "2        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "3        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "4        2020-07-11 12:13:52.365  tyljI8NkEeql1A5WxvNUrQ   \n",
       "...                          ...                     ...   \n",
       "1084658  2020-04-12 00:46:11.045  C3DnznwuEeqEUA6YVkoxuQ   \n",
       "1084659  2020-11-22 05:39:34.297  bx0OtcZQEeq3ahK57vJ81Q   \n",
       "1084660  2020-04-12 01:01:38.332  C3DnznwuEeqEUA6YVkoxuQ   \n",
       "1084661  2020-08-03 02:24:59.278  fOFFBdTSEeqwjRINUYbZPQ   \n",
       "1084662  2020-08-03 01:50:47.766  _DX3PtTcEeqBeA5fY9gYEQ   \n",
       "\n",
       "        peer_assignment_review_schema_part_prompt_score  \\\n",
       "0                                     Challenge (score)   \n",
       "1                                     Selection (score)   \n",
       "2                                   Application (score)   \n",
       "3                                       Insight (score)   \n",
       "4                                      Approach (score)   \n",
       "...                                                 ...   \n",
       "1084658                                             NaN   \n",
       "1084659                                             NaN   \n",
       "1084660                                             NaN   \n",
       "1084661                                             NaN   \n",
       "1084662                                             NaN   \n",
       "\n",
       "         peer_assignment_review_schema_part_option_score  \\\n",
       "0                                                    3.0   \n",
       "1                                                    3.0   \n",
       "2                                                    2.0   \n",
       "3                                                    3.0   \n",
       "4                                                    3.0   \n",
       "...                                                  ...   \n",
       "1084658                                              NaN   \n",
       "1084659                                              NaN   \n",
       "1084660                                              NaN   \n",
       "1084661                                              NaN   \n",
       "1084662                                              NaN   \n",
       "\n",
       "        peer_assignment_review_schema_part_prompt_free_response  \\\n",
       "0        Feedback (ungraded):The submission’s challenge...        \n",
       "1        Feedback (ungraded):The submission’s tool sele...        \n",
       "2        Feedback (ungraded):The submission’s tool appl...        \n",
       "3        Feedback (ungraded):The submission’s insight d...        \n",
       "4        Feedback (ungraded):The submission’s approach ...        \n",
       "...                                                    ...        \n",
       "1084658                                                NaN        \n",
       "1084659                                                NaN        \n",
       "1084660                                                NaN        \n",
       "1084661                                                NaN        \n",
       "1084662                                                NaN        \n",
       "\n",
       "        peer_review_part_free_response_text  \n",
       "0                  search for higher ground  \n",
       "1                         removing barriers  \n",
       "2                          understanding it  \n",
       "3              drilling down to the essence  \n",
       "4              increasing speed of learning  \n",
       "...                                     ...  \n",
       "1084658                                 NaN  \n",
       "1084659                                 NaN  \n",
       "1084660                                 NaN  \n",
       "1084661                                 NaN  \n",
       "1084662                                 NaN  \n",
       "\n",
       "[1084663 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_df = (score_responses # what each reviewer scored each assignment, by component on the analytic scale\n",
    "              .merge(schema_options) # what information was presented to the reviewer (what was the prompt?)\n",
    "              .merge(schema)[[\n",
    "                  'peer_review_id',\n",
    "                  'peer_assignment_review_schema_part_prompt',\n",
    "                  'peer_assignment_review_schema_part_order',\n",
    "                  'peer_assignment_review_schema_part_option_score']]\n",
    "              .merge(human_readable_text_responses,\n",
    "                     on=['peer_review_id', 'peer_assignment_review_schema_part_order'],\n",
    "                     how='outer',\n",
    "                     suffixes=['_score', '_free_response'],\n",
    "                     sort=True) # The written responses to each component of the rubric AND the prompts\n",
    "              .merge(reviews, on=['peer_review_id'], how='outer')#[:-6] # the last 6 have no scores, but I should leave them as NA values to be dealt with later. This is not the time for cleaning. Keep the data raw until the analysis.\n",
    "             )[['peer_review_id',\n",
    "                'uva_peer_assignments_user_id',\n",
    "                'peer_review_created_ts',\n",
    "                'peer_submission_id',\n",
    "                'peer_assignment_review_schema_part_prompt_score',\n",
    "                'peer_assignment_review_schema_part_option_score',\n",
    "                'peer_assignment_review_schema_part_prompt_free_response',\n",
    "                'peer_review_part_free_response_text']]\n",
    "\n",
    "display(reviews_df)\n",
    "# reviews_df.to_csv('bin/reviews_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2db7d9-081b-4d59-868f-caf923065804",
   "metadata": {},
   "source": [
    "## Submissions\n",
    "\n",
    "cleared_submissions.csv is a subset of the Coursera submissions.csv table.  \n",
    "It relies on criteria defined in a set of SQL queries\n",
    "\n",
    "These queries are documented in [submission_queries.md](http://as-alesl-nlp.dyn.gsu.edu:31151/hub/user-redirect/lab/tree/shared/2020_06_10_bad_reviewer/src/submission_queries.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3794dc57-ce92-42a9-8b5b-6bf4e0517c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some reviews are associated with submission IDs that do not exist in the submissions table provided by Coursera\n",
      "1,083,641 submission ids are reflected in the submissions table; 1,022 are not.\n"
     ]
    }
   ],
   "source": [
    "submissions = pd.read_csv('data/coursera_tables/peer_submissions.csv', escapechar='\\\\', on_bad_lines='warn')\n",
    "print(f'Some reviews are associated with submission IDs that do not exist in the submissions table provided by Coursera')\n",
    "submissions_represented = reviews_df.peer_submission_id.isin(submissions.peer_submission_id).value_counts()\n",
    "print(f'{submissions_represented[1]:,} submission ids are reflected in the submissions table; {submissions_represented[0]:,} are not.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969580a5-d2ab-49fb-bae4-09ff7d1cae87",
   "metadata": {},
   "source": [
    "### Which submissions were cleared in the SQL database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff116452-51c5-47a5-a4bf-7c6235cbca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users who submitted: 43,167\n",
      "Number of unique users who were cleared: 36,623\n",
      "184,420 submissions, of 221,043 submissions in total, would be excluded from reviews_df if we only considered cleared submissions.\n"
     ]
    }
   ],
   "source": [
    "cleared_submissions = pd.read_csv('bin/cleared_submissions.csv', escapechar='\\\\', on_bad_lines='warn')\n",
    "submissions['is_cleared'] = submissions.peer_submission_id.isin(cleared_submissions.peer_submission_id)\n",
    "\n",
    "print(f'Number of unique users who submitted: {submissions.uva_peer_assignments_user_id.nunique():,}')\n",
    "print(f'Number of unique users who were cleared: {submissions[submissions.is_cleared].uva_peer_assignments_user_id.nunique():,}')\n",
    "\n",
    "excluded = submissions[~submissions.is_cleared].peer_submission_id.nunique()\n",
    "total = submissions.peer_submission_id.nunique()\n",
    "print(f'{excluded:,} submissions, of {total:,} submissions in total, would be excluded from reviews_df if we only considered cleared submissions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d7db1-fcfb-4f18-80eb-1589e6a0069c",
   "metadata": {},
   "source": [
    "### How many times was each submission skipped by peer reviewers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f9d049a-f7f6-4d0b-a273-cb7662900678",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_skips = pd.read_csv('data/coursera_tables/peer_skips.csv', escapechar='\\\\', on_bad_lines='warn')\n",
    "\n",
    "submissions['num_skips'] = (submission_skips\n",
    "                            .value_counts(subset='peer_submission_id')\n",
    "                            .reindex(index=submissions.peer_submission_id)\n",
    "                            .fillna(0)\n",
    "                            .astype(int)\n",
    "                            .values\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84acd98-47a2-41a6-b706-29bc80db8ab9",
   "metadata": {},
   "source": [
    "### Add the text of each parsed submission.\n",
    "These are the only submissions we actually care about.\n",
    "\n",
    "Also mark which submissions were written by users who posted in the discussion forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f18783-a253-4126-a584-1b06dd81777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 text files have peer_assignments_user_id values that are not in the cleared_submissions table.\n",
      "27,909 examples, and 3,216 of those samples come from users with posts.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_submission_id</th>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>peer_submission_score</th>\n",
       "      <th>num_skips</th>\n",
       "      <th>has_post</th>\n",
       "      <th>is_cleared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDdVsMGhEemiSwrCiJNKAg</td>\n",
       "      <td>0000e5af02da0c7575b3ebd346b55b29f959e90f</td>\n",
       "      <td>Reflection – visualization\\n\\nChallenge      &amp;...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x6_F_AF4EeqBNgqlMZTYEw</td>\n",
       "      <td>0002c0f31f5c8456bd360dfcd089a64f444e2de0</td>\n",
       "      <td>Assignment :\\n\\n1. Challenge: Describe your ch...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5IVymkAeEeyWsA72VEvfZw</td>\n",
       "      <td>00030b378ea62d60a177113b7854eb26cc29e1a9</td>\n",
       "      <td>VISUALIZATION\\n\\nChallenge    I am part of the...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LCRPeX7LEeubEg4S-1QqIw</td>\n",
       "      <td>000458f7d47a0b6414f9146258829170ae3ed6a9</td>\n",
       "      <td>The main item is usually the focal point of th...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NGPJ3skwEeuLjgr2Ka7enw</td>\n",
       "      <td>00069909160c6bcd9836cdb23e35b1fdaf56d0c3</td>\n",
       "      <td>Storytelling is when narratives people tell ab...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28342</th>\n",
       "      <td>LgcsFcfEEemRWg4GTNs16g</td>\n",
       "      <td>fff43ee22d85efffada33d73f953c0d814d90290</td>\n",
       "      <td>Peter Vogt - Design Thinking Reflection - Lear...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28343</th>\n",
       "      <td>CrXeU6N6Eeq5qg5t3Q_jkQ</td>\n",
       "      <td>fff56a1858c62540bd76bad23db07a2fbfa963fe</td>\n",
       "      <td>STORYTELLING AS A TOOL FOR STRATEGIC CHANGES\\n...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28344</th>\n",
       "      <td>vXlp8YvQEemLCQ6udTRPUg</td>\n",
       "      <td>fff7364558963fb9fa218f2fa08d5d2767992207</td>\n",
       "      <td>Junio 2019 Storytelling Jose Vergara\\n\\nChalle...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28345</th>\n",
       "      <td>qZ-lqiCnEemqyApQiwO8gA</td>\n",
       "      <td>fffa6add42713b8b1e2a5158616f780997bbda49</td>\n",
       "      <td>Reflexion - Mind Mapping\\n\\nChallenge &amp; Select...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28346</th>\n",
       "      <td>e0_w1n5NEeubEg4S-1QqIw</td>\n",
       "      <td>fffbf02f0028d138811ed7f33682dea65294ddab</td>\n",
       "      <td>AMAZING STEPS TO LAUNCH YOUR ORIFLAME BUSINESS...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27909 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           peer_submission_id              uva_peer_assignments_user_id  \\\n",
       "0      LDdVsMGhEemiSwrCiJNKAg  0000e5af02da0c7575b3ebd346b55b29f959e90f   \n",
       "1      x6_F_AF4EeqBNgqlMZTYEw  0002c0f31f5c8456bd360dfcd089a64f444e2de0   \n",
       "2      5IVymkAeEeyWsA72VEvfZw  00030b378ea62d60a177113b7854eb26cc29e1a9   \n",
       "3      LCRPeX7LEeubEg4S-1QqIw  000458f7d47a0b6414f9146258829170ae3ed6a9   \n",
       "4      NGPJ3skwEeuLjgr2Ka7enw  00069909160c6bcd9836cdb23e35b1fdaf56d0c3   \n",
       "...                       ...                                       ...   \n",
       "28342  LgcsFcfEEemRWg4GTNs16g  fff43ee22d85efffada33d73f953c0d814d90290   \n",
       "28343  CrXeU6N6Eeq5qg5t3Q_jkQ  fff56a1858c62540bd76bad23db07a2fbfa963fe   \n",
       "28344  vXlp8YvQEemLCQ6udTRPUg  fff7364558963fb9fa218f2fa08d5d2767992207   \n",
       "28345  qZ-lqiCnEemqyApQiwO8gA  fffa6add42713b8b1e2a5158616f780997bbda49   \n",
       "28346  e0_w1n5NEeubEg4S-1QqIw  fffbf02f0028d138811ed7f33682dea65294ddab   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Reflection – visualization\\n\\nChallenge      &...   \n",
       "1      Assignment :\\n\\n1. Challenge: Describe your ch...   \n",
       "2      VISUALIZATION\\n\\nChallenge    I am part of the...   \n",
       "3      The main item is usually the focal point of th...   \n",
       "4      Storytelling is when narratives people tell ab...   \n",
       "...                                                  ...   \n",
       "28342  Peter Vogt - Design Thinking Reflection - Lear...   \n",
       "28343  STORYTELLING AS A TOOL FOR STRATEGIC CHANGES\\n...   \n",
       "28344  Junio 2019 Storytelling Jose Vergara\\n\\nChalle...   \n",
       "28345  Reflexion - Mind Mapping\\n\\nChallenge & Select...   \n",
       "28346  AMAZING STEPS TO LAUNCH YOUR ORIFLAME BUSINESS...   \n",
       "\n",
       "       peer_submission_score  num_skips  has_post is_cleared  \n",
       "0                       15.0        0.0     False       True  \n",
       "1                       17.0        0.0     False       True  \n",
       "2                       14.0        0.0     False       True  \n",
       "3                       18.0        0.0     False       True  \n",
       "4                       18.0        0.0     False       True  \n",
       "...                      ...        ...       ...        ...  \n",
       "28342                   16.0        0.0     False       True  \n",
       "28343                   17.0        0.0     False       True  \n",
       "28344                   17.0        0.0      True       True  \n",
       "28345                   12.0        0.0     False       True  \n",
       "28346                   17.0        0.0     False       True  \n",
       "\n",
       "[27909 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = pd.read_json('data/cleared_txts.jsonl', lines=True, orient='records')\n",
    "texts['id'] = texts['id'].str.split('_').str[1]\n",
    "\n",
    "labelled_txts = pd.read_json('data/labelled_subs_with_posts.jsonl', orient='records', lines=True)\n",
    "labelled_txts['id'] = labelled_txts['id'].str.split('_').str[1]\n",
    "texts['has_post'] = texts.id.isin(labelled_txts.id)\n",
    "\n",
    "submissions_df = (texts\n",
    "                  .drop(['label'], axis=1)\n",
    "                  .rename(columns={'id': 'uva_peer_assignments_user_id'})\n",
    "                  .merge(submissions[submissions.is_cleared],\n",
    "                         on=['uva_peer_assignments_user_id'],\n",
    "                         how='left')\n",
    "                 )[['peer_submission_id',\n",
    "                    'uva_peer_assignments_user_id',\n",
    "                    'text',\n",
    "                    'peer_submission_score',\n",
    "                    'num_skips',\n",
    "                    'has_post',\n",
    "                    'is_cleared']]\n",
    "\n",
    "print(f'{submissions_df[submissions_df.peer_submission_id.isna()].shape[0]} text files have peer_assignments_user_id values that are not in the cleared_submissions table.')\n",
    "submissions_df = submissions_df.dropna(subset=['peer_submission_score'])\n",
    "\n",
    "print(f'{submissions_df.shape[0]:,} examples, and {submissions_df.has_post.sum():,} of those samples come from users with posts.')\n",
    "\n",
    "display(submissions_df)\n",
    "# submissions_df.to_csv('bin/submissions_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54286792-f7ad-4dae-b1f2-5730ceb6c665",
   "metadata": {},
   "source": [
    "## Starting Correlation\n",
    "\n",
    "Please keep in mind that the peer_submission_score here is the one provided by Coursera. This is not the simple average of the peer review scores, so the scores we calculate will diverge from this if we use a simple average. See the section **Why aren't peer_submission_scores the average of the review scores??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c28eef42-c106-4e0a-92f0-cc77c9bb2294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_submission_score</th>\n",
       "      <th>num_skips</th>\n",
       "      <th>has_post</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>peer_submission_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019220</td>\n",
       "      <td>0.021417</td>\n",
       "      <td>0.111723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_skips</th>\n",
       "      <td>-0.019220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083510</td>\n",
       "      <td>0.010441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_post</th>\n",
       "      <td>0.021417</td>\n",
       "      <td>0.083510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>0.111723</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       peer_submission_score  num_skips  has_post  word_count\n",
       "peer_submission_score               1.000000  -0.019220  0.021417    0.111723\n",
       "num_skips                          -0.019220   1.000000  0.083510    0.010441\n",
       "has_post                            0.021417   0.083510  1.000000    0.031464\n",
       "word_count                          0.111723   0.010441  0.031464    1.000000"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions_df['word_count'] = submissions_df.text.str.split(' ').str.len()\n",
    "submissions_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0415fe3-5a1d-44c8-b2c8-2ee7f9f3af73",
   "metadata": {},
   "source": [
    "# Test Bed\n",
    "\n",
    "Commands that I don't want to delete because they took a while to write, but don't really do anything at this point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e721b83-0d03-413b-90d4-fc5e2b8d9317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total labelled submissions is 6293\n",
      "num labelled submissions reflected in submissions_df is 6230\n",
      "num labelled submissions reflected in Coursera submissions is 6293\n"
     ]
    }
   ],
   "source": [
    "labelled_txts = pd.read_json('data/labelled_txts/all_labelled_submissions_6293.jsonl', orient='records', lines=True)\n",
    "labelled_txts['id'] = labelled_txts['id'].str.split('_').str[1]\n",
    "# display(labelled_txts)\n",
    "\n",
    "# The following is because some labelled submissions were labelled/annotated before we settled on our final criteria\n",
    "# They can safely be ignored.\n",
    "\n",
    "print('total labelled submissions is', labelled_txts.shape[0])\n",
    "print('num labelled submissions reflected in Coursera submissions is', labelled_txts[labelled_txts.id.isin(submissions.uva_peer_assignments_user_id)].shape[0])\n",
    "print('num labelled submissions reflected in our submissions_df is', labelled_txts[labelled_txts.id.isin(submissions_df.uva_peer_assignments_user_id)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4685e89-b6d5-473f-839e-1b206d4a961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total labelled submissions is 3216\n",
      "num labelled submissions reflected in data_view is 3216\n",
      "num labelled submissions reflected in cleared_submissions is 3216\n"
     ]
    }
   ],
   "source": [
    "# The texts we care most about our the submissions from users with posts\n",
    "# These ones are consistent.\n",
    "labelled_txts = pd.read_json('data/labelled_txts/all_with_posts.jsonl', orient='records', lines=True)\n",
    "labelled_txts['id'] = labelled_txts['id'].str.split('_').str[1]\n",
    "\n",
    "print('total labelled submissions is', labelled_txts.shape[0])\n",
    "print('num labelled submissions reflected in data_view is', labelled_txts[labelled_txts.id.isin(human_readable_scores_and_responses_with_reviews_and_author.uva_peer_assignments_user_id_author)].shape[0])\n",
    "print('num labelled submissions reflected in cleared_submissions is', labelled_txts[labelled_txts.id.isin(submissions.uva_peer_assignments_user_id)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "218f7595-8db0-47a4-aeac-e04dd7f23a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ids 3216\n",
      "Unique texts 3057\n"
     ]
    }
   ],
   "source": [
    "# While we are here. Let's see how many duplicate values we have...\n",
    "\n",
    "print('Unique ids', labelled_txts.id.nunique())\n",
    "print('Unique texts', labelled_txts.data.nunique())\n",
    "display(labelled_txts[labelled_txts.duplicated(subset=['data'], keep=False)].data.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d8690-2a20-47a2-90ef-4ba326644a47",
   "metadata": {},
   "source": [
    "How many duplicate reviews are there? Did coursera record duplicate reviews, or did I do that somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd149fc9-b6db-4071-9e9c-bfd06ef95cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_review_id</th>\n",
       "      <th>peer_submission_id</th>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th>peer_review_created_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [peer_review_id, peer_submission_id, uva_peer_assignments_user_id, peer_review_created_ts]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_review_id</th>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th>peer_review_created_ts</th>\n",
       "      <th>peer_submission_id</th>\n",
       "      <th>peer_assignment_review_schema_part_prompt_score</th>\n",
       "      <th>peer_assignment_review_schema_part_option_score</th>\n",
       "      <th>peer_assignment_review_schema_part_prompt_free_response</th>\n",
       "      <th>peer_review_part_free_response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [peer_review_id, uva_peer_assignments_user_id, peer_review_created_ts, peer_submission_id, peer_assignment_review_schema_part_prompt_score, peer_assignment_review_schema_part_option_score, peer_assignment_review_schema_part_prompt_free_response, peer_review_part_free_response_text]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(reviews[reviews.duplicated()])\n",
    "display(reviews_df[reviews_df.duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7eaf7c1-9a48-4d8e-8498-973b7804d807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_review_id</th>\n",
       "      <th>peer_submission_id</th>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th>peer_review_created_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144323</th>\n",
       "      <td>a93jYDdOEeeTXBLd9rJhog</td>\n",
       "      <td>JGwq0TccEeesQRJzrNdi7A</td>\n",
       "      <td>121ade9d078639b186c58f9cd2aaced28dc6dc75</td>\n",
       "      <td>2017-05-12 20:06:01.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144324</th>\n",
       "      <td>wJFFnzgEEeeVrA7fHHMkEg</td>\n",
       "      <td>6_j1AjfhEeeTXBLd9rJhog</td>\n",
       "      <td>121ade9d078639b186c58f9cd2aaced28dc6dc75</td>\n",
       "      <td>2017-05-13 17:51:11.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144325</th>\n",
       "      <td>jcvdljgBEeeVrA7fHHMkEg</td>\n",
       "      <td>7oUR7jf2EeeSURIzKx1jwA</td>\n",
       "      <td>121ade9d078639b186c58f9cd2aaced28dc6dc75</td>\n",
       "      <td>2017-05-13 17:28:18.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144326</th>\n",
       "      <td>g_vdLzgGEeeSURIzKx1jwA</td>\n",
       "      <td>S6IA7Df2EeesQRJzrNdi7A</td>\n",
       "      <td>121ade9d078639b186c58f9cd2aaced28dc6dc75</td>\n",
       "      <td>2017-05-13 18:03:49.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144327</th>\n",
       "      <td>g_u1gzgGEee6YQrlQL-Uag</td>\n",
       "      <td>S6IA7Df2EeesQRJzrNdi7A</td>\n",
       "      <td>121ade9d078639b186c58f9cd2aaced28dc6dc75</td>\n",
       "      <td>2017-05-13 18:03:49.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144328</th>\n",
       "      <td>uoJPRzgKEee6YQrlQL-Uag</td>\n",
       "      <td>6C57_DgCEeeSURIzKx1jwA</td>\n",
       "      <td>121ade9d078639b186c58f9cd2aaced28dc6dc75</td>\n",
       "      <td>2017-05-13 18:33:58.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                peer_review_id      peer_submission_id  \\\n",
       "144323  a93jYDdOEeeTXBLd9rJhog  JGwq0TccEeesQRJzrNdi7A   \n",
       "144324  wJFFnzgEEeeVrA7fHHMkEg  6_j1AjfhEeeTXBLd9rJhog   \n",
       "144325  jcvdljgBEeeVrA7fHHMkEg  7oUR7jf2EeeSURIzKx1jwA   \n",
       "144326  g_vdLzgGEeeSURIzKx1jwA  S6IA7Df2EeesQRJzrNdi7A   \n",
       "144327  g_u1gzgGEee6YQrlQL-Uag  S6IA7Df2EeesQRJzrNdi7A   \n",
       "144328  uoJPRzgKEee6YQrlQL-Uag  6C57_DgCEeeSURIzKx1jwA   \n",
       "\n",
       "                    uva_peer_assignments_user_id   peer_review_created_ts  \n",
       "144323  121ade9d078639b186c58f9cd2aaced28dc6dc75  2017-05-12 20:06:01.477  \n",
       "144324  121ade9d078639b186c58f9cd2aaced28dc6dc75  2017-05-13 17:51:11.986  \n",
       "144325  121ade9d078639b186c58f9cd2aaced28dc6dc75  2017-05-13 17:28:18.316  \n",
       "144326  121ade9d078639b186c58f9cd2aaced28dc6dc75  2017-05-13 18:03:49.337  \n",
       "144327  121ade9d078639b186c58f9cd2aaced28dc6dc75  2017-05-13 18:03:49.336  \n",
       "144328  121ade9d078639b186c58f9cd2aaced28dc6dc75  2017-05-13 18:33:58.802  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviews_df.iloc[755643:755650]\n",
    "reviews[reviews.uva_peer_assignments_user_id == '121ade9d078639b186c58f9cd2aaced28dc6dc75']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd8f6d-38c5-4da3-8638-e44a2c8b6542",
   "metadata": {},
   "source": [
    "### Why aren't peer_submission_scores the average of the review scores??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "564c948d-196c-4347-8898-28aeb8d71573",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv('data/coursera_tables/peer_submission_part_scores.csv')\n",
    "scores = scores.merge(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4c4fda39-3f8d-46e9-9b9c-7bf7303d31c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "NA Score Recorded.\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statistics as stats\n",
    "\n",
    "def arbitrate(x):\n",
    "    '''\n",
    "    First, take the mode. If there are multiple modes, return all of them.\n",
    "    [1, 3, 3] --> 3\n",
    "    [1, 2, 3] --> 1, 2, 3\n",
    "    \n",
    "    Then, take the mean of the modes:\n",
    "    3 --> 3\n",
    "    1, 2, 3 --> 2\n",
    "    \n",
    "    This appears to be how Coursera calculates the essay grade.\n",
    "    '''\n",
    "    return np.mean(stats.multimode(x))\n",
    "\n",
    "def calculate_score(sub_id, method='arbitrate_parts'):\n",
    "    # Get info about the submission, direct from Coursera table\n",
    "    submission_info = submissions[submissions['peer_submission_id']==sub_id]\n",
    "\n",
    "    # Get reviews associated with the submission\n",
    "    submission_reviews = reviews_df[reviews_df['peer_submission_id']==sub_id]\n",
    "\n",
    "    # Select only reviews before/when score was made available\n",
    "    if pd.notnull(submission_info.peer_submission_score_available_ts.values):\n",
    "        timely_reviews = submission_reviews[submission_reviews\n",
    "                                            .peer_review_created_ts.values\n",
    "                                            <=\n",
    "                                            submission_info\n",
    "                                            .peer_submission_score_available_ts\n",
    "                                            .values]\n",
    "    \n",
    "    # Get score recorded in Coursera table\n",
    "    coursera_score = submission_info.peer_submission_score.iloc[0]\n",
    "    \n",
    "    # Some submissions have null for final score.\n",
    "    if pd.isnull(coursera_score):\n",
    "        return 'NA Score Recorded.'\n",
    "    \n",
    "    # Try averaging all reviews\n",
    "    if method=='average_all':\n",
    "        my_score = np.mean(submission_reviews\n",
    "                           .groupby('peer_review_id')['peer_assignment_review_schema_part_option_score']\n",
    "                           .sum())\n",
    "    \n",
    "    # Try arbitrating by partial scores\n",
    "    elif method=='arbitrate_parts':\n",
    "        my_score = sum(timely_reviews[['uva_peer_assignments_user_id',\n",
    "                                           'peer_assignment_review_schema_part_prompt_score',\n",
    "                                           'peer_assignment_review_schema_part_option_score']]\n",
    "                       .dropna()\n",
    "                       .pivot(index='uva_peer_assignments_user_id',\n",
    "                              columns='peer_assignment_review_schema_part_prompt_score',\n",
    "                              values='peer_assignment_review_schema_part_option_score')\n",
    "                       .agg(arbitrate)\n",
    "                   )\n",
    "\n",
    "    coursera_score = submission_info.peer_submission_score.iloc[0]\n",
    "\n",
    "    # Debug Procedures...\n",
    "    if coursera_score != my_score:\n",
    "        print(f'The calculated score {my_score} does not equal the recorded score {coursera_score}.')\n",
    "        \n",
    "        print('The partial scores recorded by Coursera:')\n",
    "        display(scores[scores['peer_submission_id']==sub_id].sort_values(by=['peer_assignment_review_schema_part_prompt']))\n",
    "        \n",
    "        print('All associated reviews:')\n",
    "        display(submission_reviews[['uva_peer_assignments_user_id',\n",
    "                                    'peer_assignment_review_schema_part_prompt_score',\n",
    "                                    'peer_assignment_review_schema_part_option_score']]\n",
    "                .dropna()\n",
    "                .pivot(index='uva_peer_assignments_user_id',\n",
    "                       columns='peer_assignment_review_schema_part_prompt_score',\n",
    "                       values='peer_assignment_review_schema_part_option_score'))\n",
    "        \n",
    "        print('Reviews where timestamp is before peer_submission_score_available_ts')\n",
    "        display(timely_reviews[['uva_peer_assignments_user_id',\n",
    "                                'peer_assignment_review_schema_part_prompt_score',\n",
    "                                'peer_assignment_review_schema_part_option_score']]\n",
    "                .dropna()\n",
    "                .pivot(index='uva_peer_assignments_user_id',\n",
    "                       columns='peer_assignment_review_schema_part_prompt_score',\n",
    "                       values='peer_assignment_review_schema_part_option_score'))\n",
    "\n",
    "        print('Some information about the submission:')\n",
    "        display(submission_info)\n",
    "    \n",
    "    else:\n",
    "        return 'Success!'\n",
    "\n",
    "for submission_id in reviews_df.peer_submission_id.sample(n=20):\n",
    "    print(calculate_score(submission_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b7c8875-b93f-48ed-9d2a-6e2cb8bb4a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peer_submission_id</th>\n",
       "      <th>uva_peer_assignments_user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>peer_submission_score</th>\n",
       "      <th>num_skips</th>\n",
       "      <th>has_post</th>\n",
       "      <th>is_cleared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2LfoJGirEeyZgBKRrAlULw</td>\n",
       "      <td>002edb72adc00431eec524ebdffcf0a0967455f5</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>759e7cEeEeqb0BIFdwj-7Q</td>\n",
       "      <td>0053fa62b14adc81df54ee305ec4ad17438d7975</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>jTN9gULOEeuYZBI43RQb6Q</td>\n",
       "      <td>00a9b39ee739977810c76dd7c5b01e2ef164e58a</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>JymwoRHSEeuGFQrtOYslJw</td>\n",
       "      <td>00d4a1dab1eb36a487498d42fc1a83766fcfa4b7</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>E4BHa12bEeumbAqQIoY8Bw</td>\n",
       "      <td>010dec771476398b6b24b2c0ef5fd4a66727ec40</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28150</th>\n",
       "      <td>nkjwFTUuEeulJw4UR3t4pQ</td>\n",
       "      <td>fe088508bbdf409e09561f43bbfa26af57576821</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28167</th>\n",
       "      <td>xn7GBsXeEeq3ahK57vJ81Q</td>\n",
       "      <td>fe258f8c6a7e4dd4e138415bc45909007896944a</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28181</th>\n",
       "      <td>CLTOHSQ7EeyIag7DkTyGZQ</td>\n",
       "      <td>fe56b3da78a85379f811a1085c0fc956dd502cc2</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28250</th>\n",
       "      <td>i0an_9dqEeqZbAp7cLQpmQ</td>\n",
       "      <td>ff18224fa1f9189d78e42cb8d9f12f7d1835562e</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28335</th>\n",
       "      <td>pWX-9NAuEeuoPBL_1xwTEw</td>\n",
       "      <td>ffde36a17775693ec2975723c00303112fe6f55f</td>\n",
       "      <td>Example Reflection – Visualization\\n\\nChalleng...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>969 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           peer_submission_id              uva_peer_assignments_user_id  \\\n",
       "15     2LfoJGirEeyZgBKRrAlULw  002edb72adc00431eec524ebdffcf0a0967455f5   \n",
       "28     759e7cEeEeqb0BIFdwj-7Q  0053fa62b14adc81df54ee305ec4ad17438d7975   \n",
       "68     jTN9gULOEeuYZBI43RQb6Q  00a9b39ee739977810c76dd7c5b01e2ef164e58a   \n",
       "87     JymwoRHSEeuGFQrtOYslJw  00d4a1dab1eb36a487498d42fc1a83766fcfa4b7   \n",
       "120    E4BHa12bEeumbAqQIoY8Bw  010dec771476398b6b24b2c0ef5fd4a66727ec40   \n",
       "...                       ...                                       ...   \n",
       "28150  nkjwFTUuEeulJw4UR3t4pQ  fe088508bbdf409e09561f43bbfa26af57576821   \n",
       "28167  xn7GBsXeEeq3ahK57vJ81Q  fe258f8c6a7e4dd4e138415bc45909007896944a   \n",
       "28181  CLTOHSQ7EeyIag7DkTyGZQ  fe56b3da78a85379f811a1085c0fc956dd502cc2   \n",
       "28250  i0an_9dqEeqZbAp7cLQpmQ  ff18224fa1f9189d78e42cb8d9f12f7d1835562e   \n",
       "28335  pWX-9NAuEeuoPBL_1xwTEw  ffde36a17775693ec2975723c00303112fe6f55f   \n",
       "\n",
       "                                                    text  \\\n",
       "15     Example Reflection – Visualization\\n\\nChalleng...   \n",
       "28     Example Reflection – Visualization\\n\\nChalleng...   \n",
       "68     Example Reflection – Visualization\\n\\nChalleng...   \n",
       "87     Example Reflection – Visualization\\n\\nChalleng...   \n",
       "120    Example Reflection – Visualization\\n\\nChalleng...   \n",
       "...                                                  ...   \n",
       "28150  Example Reflection – Visualization\\n\\nChalleng...   \n",
       "28167  Example Reflection – Visualization\\n\\nChalleng...   \n",
       "28181  Example Reflection – Visualization\\n\\nChalleng...   \n",
       "28250  Example Reflection – Visualization\\n\\nChalleng...   \n",
       "28335  Example Reflection – Visualization\\n\\nChalleng...   \n",
       "\n",
       "       peer_submission_score  num_skips  has_post is_cleared  \n",
       "15                      18.0        0.0     False       True  \n",
       "28                      18.0        0.0     False       True  \n",
       "68                      18.0        0.0     False       True  \n",
       "87                      18.0        0.0     False       True  \n",
       "120                     18.0        0.0      True       True  \n",
       "...                      ...        ...       ...        ...  \n",
       "28150                   14.0        0.0      True       True  \n",
       "28167                   18.0        0.0     False       True  \n",
       "28181                   17.0        0.0     False       True  \n",
       "28250                   18.0        0.0     False       True  \n",
       "28335                   18.0        0.0     False       True  \n",
       "\n",
       "[969 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions_df[submissions_df.text.str.startswith('Example Reflection – Visualization')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
